# Web Scraper for Product Data

Этот проект представляет собой скрипт для сбора данных о товарах с сайта [Maxidom](https://www.maxidom.ru). Скрипт выполняет парсинг данных о товарах и их ценах из указанной категории и сохраняет их в базу данных PostgreSQL.

## Описание

Скрипт реализует парсинг страниц каталога товаров. На каждой странице скрипт извлекает информацию о названии и цене каждого товара, затем переходит на следующую страницу, если она доступна, и продолжает сбор данных. После завершения сбора данные сохраняются в базу данных PostgreSQL, используя SQLAlchemy ORM.

Также в проекте присутствуют дополнительные файлы для инициализации базы данных и запуска сервера на FastAPI.

### Основные функции

- **fetch_page(url, headers)**: отправляет GET-запрос по указанному URL, обрабатывает ошибки доступа и возвращает HTML-код страницы.
- **parse_product_data(soup)**: извлекает данные о товарах с одной страницы, включая название и цену, и возвращает их в виде списка словарей.
- **get_next_page_url(soup, base_url)**: определяет URL следующей страницы, если она доступна.
- **collect_product_data(start_url, delay=1)**: основной цикл сбора данных по всем страницам в категории. Скрипт переходит на следующую страницу и делает паузу (по умолчанию 1 секунда) для снижения нагрузки на сервер.
- **save_products_to_db(products)**: сохраняет собранные данные о товарах в базу данных PostgreSQL, используя SQLAlchemy.

## Установка

1. Клонируйте репозиторий.
   
```bash
   git clone <URL вашего репозитория>
   cd <название папки репозитория>
```

2. Установите зависимости.
   
```bash
   pip install requests beautifulsoup4 pandas aiohttp "fastapi[standard]" sqlalchemy[asyncpg] asyncpg uvicorn psycopg2-binary
```

3. Настройте подключение к базе данных PostgreSQL. Обновите переменную `DATABASE_URL` в основном скрипте (`scraper.py`) с корректными данными для вашей базы данных.

## Использование

1. Задайте категорию товаров для парсинга, заменив переменную `category` на нужное значение. Например:
   
```python
   category = "nasosnoe-oborudovanie"
```

2. Запустите файл `init_db.py` для инициализации базы данных и создания необходимых таблиц:

```bash
   python init_db.py
```

3. Запустите скрипт для сбора данных:
   
```bash
   python scraper.py
```

4. Для запуска сервера FastAPI используйте файл `start.bat`. Это можно сделать двойным щелчком по файлу или из командной строки:

```bash
   start.bat
```

Сервер FastAPI будет запущен в режиме разработки, и логи будут сохраняться в файл `server.log`.

## Файлы проекта

### 1. `main.py`
Основной скрипт для сбора данных о товарах с сайта и сохранения их в базу данных.

### 2. `init_db.py`
Скрипт для инициализации базы данных. Создаёт таблицы в базе данных PostgreSQL.

### 3. `start.bat`
Скрипт для запуска сервера FastAPI. Запускает сервер в фоне и сохраняет логи в файл `server.log`.

## Пример структуры таблицы базы данных

Таблица `products` содержит следующие колонки:
- **id** — уникальный идентификатор товара.
- **name** — название товара.
- **price** — цена товара.

### Пример данных
| id  | Название          | Цена            |
|-----|-------------------|-----------------|
| 1   | Водяной насос 1   | 5 000 руб.      |
| 2   | Насос погружной 2 | 7 500 руб.      |

## Зависимости

- **Python 3.x**
- **requests** — для отправки HTTP-запросов
- **beautifulsoup4** — для парсинга HTML-кода
- **pandas** — для работы с таблицами
- **SQLAlchemy** — для работы с базой данных PostgreSQL
- **FastAPI** — для создания веб-приложения
- **Uvicorn** — для запуска сервера FastAPI
- **psycopg2-binary** — для взаимодействия с PostgreSQL

## Дополнительно

- **`init_db.py`**: Этот файл необходим для создания таблиц в базе данных перед тем, как вы начнёте сбор данных. Используйте его каждый раз, когда вам нужно инициализировать или пересоздать базу данных.

- **`start.bat`**: Удобный способ быстро запустить сервер FastAPI. Сервер можно использовать для предоставления данных другим клиентам или для тестирования работы с базой данных.

## Примечания

- При необходимости измените задержку между запросами, чтобы избежать избыточной нагрузки на сервер (`delay` в функции `collect_product_data`).
- Убедитесь, что у вас установлена и настроена база данных PostgreSQL, а также что вы используете корректные данные для подключения.

